---
title: "A Gentle Introduction into Structural Causal Models"
author: 
- Daniel Saggau $\boldsymbol{\cdot}$ `daniel.saggau@campus.lmu.de`
- Department of Statistics, Ludwig Maximilian University Munich, Germany
date: " April 5th, 2021"
output: 
  pdf_document:
        number_sections: yes
        fig_caption: yes
fontsize: 12
linestretch: 1.5
citation_package: --biblatex
bibliography: [ref.bib]
nocite: '@*'
abtract: The interest in understanding relationships of variables beyond co-occurrence has increased the popularity of causal modelling. To provide a comprehensive understanding of causal modelling, I introduce two prominent causal model specifications namely (1) Bayesian Causal Networks (BCN) and (2) Structural Causal Models (SCM), focusing on the latter.Probabilistic specifications such as a BCN cast a model based on conditional probabilities. SCMs cast a model based on assignment functions and extend probabilistic models by specifying the data generating process rather than solely utilizing conditional probabilities. Another difference between these models is their ability to address different queries such as *predictions*, *interventions* and *counterfactuals*. These queries are part of Pearl's causal hierarchy (2009). Pearl matches these queries with their respective actions namely *observing*, *doing* and *imagining*. I compare the feasibility of addressing these queries and undertaking respective actions for both specifications. To contextualize SCMs within the field of causality, I also discuss the role of time in causal inference and provide a brief overview of the history of causal modelling. This paper uses various directed acyclic graphs to highlight the differences in these modelling approaches. The insights of this paper can be used as a baseline for subsequent research on structural causal models.

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction 

Most undergraduate students that take a class in introductory statistics have heard the phrase 'correlation does not imply causation'.
While correlation implies co-occurrence, people are frequently interested in a causal understanding of relationships between variables.
One may argue that especially in high stake settings, algorithmic decision making based on co-occurrence is insufficient [@bareinboim2020pearl].
There are different approaches on how to model causal relationships.
Structural Causal Models and Bayesian Causal Networks are arguably the two most prominent causal models.
Bayesian Causal Networks (BCN) cast a model based on conditional probabilities.
All relationships are defined in **conditional probabilities.**
BCNs ignore exogenous variables [@pearl2009causality].
In Figure 1 we can see an example of what a probabilistic model looks like in a directed acylic graph.
Our nodes are the white circles.
The edges are the arrows, defined by the conditional probabilities.
All variables in our graph are observed variables. 
C is our **collider** variable because the affect of A on C and T on C collide [@pearl2009causality].

```{tikz, notwell,  fig.cap ="Probabilistic Model",  fig.align="center", echo =F, fig.show="hold", out.width="50%" }
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
\begin{tikzpicture}[
    sharp corners=2pt,
    inner sep=7pt,
    node distance=3cm,
    >=latex]
\tikzstyle{my node}=[draw, shape = circle, minimum height=1cm,minimum width=1cm]
\node[my node] (A){A};
\node[my node,right =1 cm of A](C){C};
\node[my node] at ($(A)!0.5!(C)-(0pt,1.5cm)$) (T) {T};
\draw[->] (A) -- (T);
\draw[->] (A) -- (C);
\draw[->] (T) -- (C);
\end{tikzpicture}
```

The field of causal inference introduced tools to combine various different sources of knowledge such as theoretical knowledge [@morgan_winship_2014] for more realistic models beyond the confinement of our observations.
Structural Causal Models (SCM) specify relationships based on **functional equations** [@pearl2009causality] including unobserved variables.
SCMs are a nonparametric modification of structural equations models (a set of functional equations) with some extensions.
These extensions are a combination of the mathematical language from graphical models and the implementation of the potential outcome framework [@pearl2012causal].
Structural equations models (SEM) are parametric causal models which are very popular in fields like economics, psychology and sociology (Pearl 2009).
One should point out that there is a lot of controversy around SEMs because many scholars challenge the value of the parameters in a SEM [@pearl2012causal].
The central idea of SCMs is to provide a model specifying an underlying data generating process, without the redundancy of creating inconsistent parameter specifications.^[Inconsistency refers to inherent nature of creating parameters based of observational data. One inherent feature of observational data is that it is seldom consistent and henceforth respective estimates are questionable.For further information see @hernan2008does] 
SCMs use assignment equations to specify an underlying data-generation-process.
Note that these equations have not always had a concise mathematical notation (Pearl, 2009).
Initially there was no sign to express the assignment equation and people used the '=' and one would e.g. write $A=B$.
But treating an equation as a **algebraic equation**, makes no sense in the causality context because this equation has no causal information.
This algebraic equation would imply that $B=A$ because the order has no concrete meaning in algebraic equations.
The problem is that the equation is symmetric.
The initial $'='$ sign was replaced with the ':=' which is asymmetric (Pearl, 2009) and called an **assignment**.
This misconception has caused a lot of challenges which I will address further on in this paper. 
As mentioned, we define variables as functions therefore a variable for example $A=f_A(B,U_A)$.
A is defined by B and the latent factor $U_A$.
To summarize, a SCM consists of a set of (autonomous) equations to generate (a) endogenous variables and (b) exogenous variables.
In figure 2 we can see a plain-vanilla structural causal model. 
The square nodes represent the latent variables.
The circle nodes represent the observed variables.
The arrows are our structural equations and depict the relationship between variables.
^[Note that there are also cyclic structural causal models but no cyclic bayesian causal networks. For further information see Pearl (2009). Due to the confined scope of this paper, I will not explore cyclic structures.]

```{tikz,fig.cap="Structural Causal Model" ,fig.align="center", echo =F}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
  \begin{tikzpicture}[
    sharp corners=2pt,
    inner sep=6pt,
    node distance=2cm,
    >=latex]
\tikzstyle{my node}=[draw, shape = circle, minimum height=1cm,minimum width=1cm]
\tikzstyle{latent}=[draw, shape = rectangle, minimum height=1cm,minimum width=1cm]
\node[my node, fill=gray!30] (A){A};
\node[latent,left of=A](UA){$U_A$};
\node[my node, fill=gray!30] at ($(A)!0.5!(A)-(0pt,1.5cm)$) (T) {T};
\node[my node,right = 1 cm of T, fill=gray!30](C){C};
\node[latent,left = 1cm of T](UT){$U_T$};
\node[latent,right = 1cm of A](UC){$U_C$};
\draw[->] (A) -- (T);
\draw[->] (UA) -- (A);
\draw[->] (UT) -- (T);
\draw[->] (UC) -- (C);
\draw[->] (A) -- (C);
\draw[->] (T) -- (C);
\end{tikzpicture}
```


Beyond the different causal model specifications, Judea Pearl (2009) introduced the hierarchy of causation.
Pearl focuses on three layers namely association, intervention and counterfactuals. 
A higher level implies a more detailed knowledge of the relationship between the variables.
The first query is association, where we examine relationships based on observations.

\footnotesize
 |Method          | Action |  Example | Usage | 
|------------------|-------------|--------------------|-------------------|
| Association $P(a|b)$               | Co-occurrence             | What happened...               |(Un-)Supervised ML, BN, Reg.  
| Intervention $P(a|do(b),c)$       | Do-manipulation           | What happens if ...            |CBN,MDP,RL    
| Counterfactual $P(a_b|a`,b`)$     | Hypotheticals   | What would have happened if...           | SCM ,PO            

Table: Pearls Hierachy of Causation (2009)

\normalsize

In table 1 we can see that machine learning (ML) methods, bayesian networks (BN) and regression models (Reg) are at the lowest level in the causal hierarchy.
These methods depend on association alone and lack information on what happens if we make changes in our root nodes (our nodes that are not caused by other variables) and what would happen if we had a different setting. 
The second query deals with interventions.
Here we can use Pearls (2009) do-calculus to examine what happens if root nodes are manipulated.
Note that there are various different types of intervention, such as atomic intervention, where we set a variable to a constant, or e.g. policy intervention where we specify a different function for a specific equation in our set of equations.
Additionally there is also off-policy intervention, where we model a different intervention that is not in our historical data based on the historical data [@oberst2019counterfactual].
Causal bayesian networks , markov decision processes (MDP) and reinforcement learning frequent these intervention methods.
The third query is counterfactual modelling. 
Here we deal with hypothetical settings. 
SCMs and potential outcome models allow for counterfactual modelling.
The reason why these models can model counterfactuals is because they also include information on the interventional distribution [@oberst2019counterfactual].
Given that e.g. BCN only entail conditional probabilities and no information on relationships outside of the observations in the data, they cannot create counterfactuals (Pearl 2009).

Another issue in this paper is understanding the relationship of time and causal modelling.
Causal models mostly disregard concise notions of time and make the strong assumption that relationships between variables hold beyond the confinement of time (Peters et al. 2017).
These vague definitions of time is more prevalent in social sciences. 
Meanwhile hard sciences deal with time in a more concise manner. 
Some research has also looked at causal models with a more concise specification of time using differential equations (Mooij et al. 2013).

To summarize, existing literature has provided an excellent introduction to structural causal models and bayesian causal networks. 
Judea Pearl (2009) provided a comprehensive and accessible introduction into this topic with his book on causality.
His work has addressed various misconceptions in social sciences, economics, causality and statistics. 
Peters et al. (2017) added to this discourse by addressing the relationship of causal modelling to physical sciences and causal inference for observational data.
Additionally, other scholars e.g. [@bareinboim2020pearl] have worked on the application of causal methods in machine learning. 
@tarka2018overview discuss the history of SEMs and SCMs.
This paper brings together these contributions. 
The objective of this paper is to provide a comprehensive summary of structural causal models and respective applications in social sciences, physical sciences and machine learning.
The insights in this paper are an abstraction of these pieces of work, offering the reading a basic understanding of the topic for future research and an overview of the current research.
The rest of the paper is structured as follows: 

# Foundations of Structural Causal Models 

Judea Pearl argues that path analysis, a method proposed by Sewall Wright in the 1920s is the foundation of modern structural causal models.
Sewall Wright, a Statistican and Geneticist, sparked the interest in causal modelling with his path analysis which subsequently was adopted by various other disciplines such as econometrics, psychometrics and sociology.
This path analysis is a structural equation model with one variable per indicator.

Aside from path diagrams also introduced graph rules for writing down relationships.

Thereafter the Norwegian Economist Trygve Haavelmo (1944) provided a modelling framework for the field of economics in is paper 'The Probability Approach in Econometrics.'
One could argue that this paper provided a new of level of sophistication to the discipline of Econometrics as a distinct field. 
Haavelmo was awarded the Nobel Memorial Prize in Economic Science in 1989 for his work on this issue. 

Causal assumptions are encoded in missing links. 

## Assumptions 

Causal assumptions differentiate causal models from association learning methods.

 | Association-based Concepts |  Causal Concepts
|--------------------------|------------------------|
| Correlation              | Randomization  
| Regression               | Confounding
| Conditional Independence | Disturbance
| Likelihood               | Error Terms      
| Odds Ratio               | Structural Coefficients       
| Propensity Score         | Spurious Correlation    

Table: Concepts in Causality and Association concepts

These causal concepts are not expressible based on distribution functions/statistical associations. (Pearl 2010)

Disturbance in SCM: Correlated and causal factor ; responsible for variation
Disturbance in Regression: Uncorrelated 

Causal assumption not testable (e.g. $Cov(U_a, U_b)=0$).
d-seperation to test assumptions in totality (cannot make assumptions in isolation).

exploit invariant characteristics of SEM whithout committing to shape. 
structural if function autonomous and invariant to change in form of other functions. 

### Causal Inference on Observational Data

Select Admissable set based on backdoor criterion.
Backdoor criterion missing in PO framework where subset is selected based on mental reasoning.
Conditional Ignorability is mirror of backdoor criterion in PO-Framework.


## Pearl Causal Hierachy 


 |Method         | CBN |  SCM
|----------------|---------------------------|------------------------|
| Prediction     | $\boldsymbol{\cdot}$ Unstable                                                                                        | $\boldsymbol{\cdot}$ Stable                 
|                | $\boldsymbol{\cdot}$ Volatile to parameter changes                                                                   | $\boldsymbol{\cdot}$ More Natural Specification 
|                | $\boldsymbol{\cdot}$ Re-Estimate entire model                                                                        | $\boldsymbol{\cdot}$ Only estimate $\Delta$ CM
|                |                                                                                                                      | 
| Intervention   | $\boldsymbol{\cdot}$ Costly for Non-Markovian Models                                                                 | $\boldsymbol{\cdot}$ Pot. Cyclic Representation
|                | $\boldsymbol{\cdot}$ Unstable(Nature CP)                                                                             | $\boldsymbol{\cdot}$ Stable(Nature Eq.)
|                | $\boldsymbol{\cdot}$ Only generic estimates($\Delta$ CP)                                                             | $\boldsymbol{\cdot}$ Context specific(Invariance of Eq.)
|                |                                                                                                                      | 
|Counterfactuals | $\boldsymbol{\cdot}$ **Impossible**                                                                                  | $\boldsymbol{\cdot}$ Possible
|                | $\boldsymbol{\cdot}$ no information on latent factors($\epsilon$)                                                    | $\boldsymbol{\cdot}$ Inclusion of latent factors


**Counterfactuals**

Process is described as follows:

(a) Abduction: Cast probability $P(u)$ as conditional probability $P(u|\epsilon)$ 
(b) Action: Exchange $(X = x)$ 
(c) Prediction: Compute $(Y = y)$

## Causal Inference and Time 

## Graphical Models 



# Conclusion

This paper provides a gentle introduction into structural causal models.
SCMs entail many features, complementing research on association learning by providing depth. 
This in turn, is of particular benefit for high stake decision settings. 
SCMs differentiate from other methods through the specification of endogenous and exogenous variables, treating the exogenous factors as pivotal components of the actual model rather than assuming they are ommitable errors that are uncorrelated. 
As suggested by Pearls Hierachy, there are different levels to learning and each higher step can do anything the prior step can but with more detail and information. 
Henceforth, as machin


# References
