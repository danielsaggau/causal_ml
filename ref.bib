@article{mooij2013ordinary,
  title={From ordinary differential equations to structural causal models: the deterministic case},
  author={Mooij, Joris M and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:1304.7920},
  year={2013}
}

@techreport{pearl2012causal,
  title={The causal foundations of structural equation modeling},
  author={Pearl, Judea},
  year={2012},
  institution={CALIFORNIA UNIV LOS ANGELES DEPT OF COMPUTER SCIENCE}
}

@book{pearl2009causality,
  title={Causality},
  author={Pearl, Judea},
  year={2009},
  publisher={Cambridge university press}
}


@book{peters_elements_2017,
	address = {Cambridge, Massachuestts},
	series = {Adaptive computation and machine learning series},
	title = {Elements of causal inference: foundations and learning algorithms},
	isbn = {978-0-262-03731-0},
	shorttitle = {Elements of causal inference},
	language = {en},
	publisher = {The MIT Press},
	author = {Peters, Jonas and Janzing, Dominik and Schölkopf, Bernhard},
	year = {2017},
	keywords = {Causation, Computer algorithms, Inference, Logic, Symbolic and mathematical, Machine learning},
	file = {Peters et al. - 2017 - Elements of causal inference foundations and lear.pdf:files/3487/Peters et al. - 2017 - Elements of causal inference foundations and lear.pdf:application/pdf}
}


@article{tarka2018overview,
  title={An overview of structural equation modeling: its beginnings, historical development, usefulness and controversies in the social sciences},
  author={Tarka, Piotr},
  journal={Quality \& quantity},
  volume={52},
  number={1},
  pages={313--354},
  year={2018},
  publisher={Springer}
}

@inbook{morgan_winship_2014, place={Cambridge}, edition={2}, series={Analytical Methods for Social Research}, title={Causal Graphs}, DOI={10.1017/CBO9781107587991.004}, booktitle={Counterfactuals and Causal Inference: Methods and Principles for Social Research}, publisher={Cambridge University Press}, author={Morgan, Stephen L. and Winship, Christopher}, year={2014}, pages={77–102}, collection={Analytical Methods for Social Research}}

@article{bareinboim2020pearl,
  title={On pearl’s hierarchy and the foundations of causal inference},
  author={Bareinboim, Elias and Correa, JD and Ibeling, Duligur and Icard, Thomas},
  journal={ACM Special Volume in Honor of Judea Pearl (provisional title)},
  year={2020}
}

@article{hernan2008does,
  title={Does obesity shorten life? The importance of well-defined interventions to answer causal questions},
  author={Hern{\'a}n, Miguel A and Taubman, Sarah L},
  journal={International journal of obesity},
  volume={32},
  number={3},
  pages={S8--S14},
  year={2008},
  publisher={Nature Publishing Group}
}

@inproceedings{oberst2019counterfactual,
  title={Counterfactual off-policy evaluation with gumbel-max structural causal models},
  author={Oberst, Michael and Sontag, David},
  booktitle={International Conference on Machine Learning},
  pages={4881--4890},
  year={2019},
  organization={PMLR}
}

@book{hardtrecht,
  author = {Moritz Hardt and Benjamin Recht},
  title = {Patterns, predictions, and actions: A story about machine learning},
  year = {2021},
  publisher = {\url{https://mlstory.org}},
  archivePrefix = {arXiv},
  eprint = {2102.05242},
  primaryClass = {cs.LG},
}

@InProceedings{creager, title = {Causal Modeling for Fairness In Dynamical Systems}, author = {Creager, Elliot and Madras, David and Pitassi, Toniann and Zemel, Richard}, booktitle = {Proceedings of the 37th International Conference on Machine Learning}, pages = {2185--2195}, year = {2020}, editor = {Hal Daumé III and Aarti Singh}, volume = {119}, series = {Proceedings of Machine Learning Research}, month = {13--18 Jul}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v119/creager20a/creager20a.pdf}, url = { http://proceedings.mlr.press/v119/creager20a.html }, abstract = {In many applications areas—lending, education, and online recommenders, for example—fairness and equity concerns emerge when a machine learning system interacts with a dynamically changing environment to produce both immediate and long-term effects for individuals and demographic groups. We discuss causal directed acyclic graphs (DAGs) as a unifying framework for the recent literature on fairness in such dynamical systems. We show that this formulation affords several new directions of inquiry to the modeler, where sound causal assumptions can be expressed and manipulated. We emphasize the importance of computing interventional quantities in the dynamical fairness setting, and show how causal assumptions enable simulation (when environment dynamics are known) and estimation by adjustment (when dynamics are unknown) of intervention on short- and long-term outcomes, at both the group and individual levels.} }

@book{barocas,
  title = {Fairness and Machine Learning},
  author = {Solon Barocas and Moritz Hardt and Arvind Narayanan},
  publisher = {fairmlbook.org},
  note = {\url{http://www.fairmlbook.org}},
  year = {2019}
}

@book{morgan_winship_2014, place={Cambridge}, edition={2}, series={Analytical Methods for Social Research}, title={Counterfactuals and Causal Inference: Methods and Principles for Social Research}, DOI={10.1017/CBO9781107587991}, publisher={Cambridge University Press}, author={Morgan, Stephen L. and Winship, Christopher}, year={2014}, collection={Analytical Methods for Social Research}}


@article{chiappa_causal_2019,
	title = {A {Causal} {Bayesian} {Networks} {Viewpoint} on {Fairness}},
	volume = {547},
	url = {http://arxiv.org/abs/1907.06430},
	doi = {10.1007/978-3-030-16744-8_1},
	abstract = {We oﬀer a graphical interpretation of unfairness in a dataset as the presence of an unfair causal path in the causal Bayesian network representing the data-generation mechanism. We use this viewpoint to revisit the recent debate surrounding the COMPAS pretrial risk assessment tool and, more generally, to point out that fairness evaluation on a model requires careful considerations on the patterns of unfairness underlying the training data. We show that causal Bayesian networks provide us with a powerful tool to measure unfairness in a dataset and to design fair models in complex unfairness scenarios.},
	language = {en},
	urldate = {2021-04-12},
	journal = {arXiv:1907.06430 [cs, stat]},
	author = {Chiappa, Silvia and Isaac, William S.},
	year = {2019},
	note = {arXiv: 1907.06430},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {3--20},
	file = {Chiappa and Isaac - 2019 - A Causal Bayesian Networks Viewpoint on Fairness.pdf:files/3447/Chiappa and Isaac - 2019 - A Causal Bayesian Networks Viewpoint on Fairness.pdf:application/pdf}
}

@article{hernan_causal_nodate,
	title = {Causal {Inference}: {What} {If}},
	language = {en},
	author = {Hernán, Miguel A and Robins, James M},
	pages = {311},
	file = {Hernán and Robins - Causal Inference What If.pdf:files/3448/Hernán and Robins - Causal Inference What If.pdf:application/pdf}
}

@article{cortes_simulation_2019,
	title = {A {Simulation} {Based} {Dynamic} {Evaluation} {Framework} for {System}-wide {Algorithmic} {Fairness}},
	url = {http://arxiv.org/abs/1903.09209},
	abstract = {We propose the use of Agent Based Models (ABMs) inside a reinforcement learning framework in order to better understand the relationship between automated decision making tools, fairness-inspired statistical constraints, and the social phenomena giving rise to discrimination towards sensitive groups. There have been many instances of discrimination occurring due to the applications of algorithmic tools by public and private institutions. Until recently, these practices have mostly gone unchecked. Given the large-scale transformation these new technologies elicit, a joint effort of social sciences and machine learning researchers is necessary. Much of the research has been done on determining statistical properties of such algorithms and the data they are trained on. We aim to complement that approach by studying the social dynamics in which these algorithms are implemented. We show how bias can be accumulated and reinforced through automated decision making, and the possibility of ﬁnding a fairness inducing policy. We focus on the case of recidivism risk assessment by considering simpliﬁed models of arrest. We ﬁnd that if we limit our attention to what is observed and manipulated by these algorithmic tools, we may determine some blatantly unfair practices as fair, illustrating the advantage of analyzing the otherwise elusive property with a system-wide model. We expect the introduction of agent based simulation techniques will strengthen collaboration with social scientists, arriving at a better understanding of the social systems affected by technology and to hopefully lead to concrete policy proposals that can be presented to policymakers for a true systemic transformation.},
	language = {en},
	urldate = {2021-04-12},
	journal = {arXiv:1903.09209 [cs]},
	author = {Cortés, Efrén Cruz and Ghosh, Debashis},
	month = mar,
	year = {2019},
	note = {arXiv: 1903.09209},
	keywords = {Computer Science - Computers and Society},
	file = {Cortés and Ghosh - 2019 - A Simulation Based Dynamic Evaluation Framework fo.pdf:files/3449/Cortés and Ghosh - 2019 - A Simulation Based Dynamic Evaluation Framework fo.pdf:application/pdf}
}

@article{kusner_counterfactual_2018,
	title = {Counterfactual {Fairness}},
	url = {http://arxiv.org/abs/1703.06856},
	abstract = {Machine learning can impact people with legal or ethical consequences when it is used to automate decisions in areas such as insurance, lending, hiring, and predictive policing. In many of these scenarios, previous decisions have been made that are unfairly biased against certain subpopulations, for example those of a particular race, gender, or sexual orientation. Since this past data may be biased, machine learning predictors must account for this to avoid perpetuating or creating discriminatory practices. In this paper, we develop a framework for modeling fairness using tools from causal inference. Our deﬁnition of counterfactual fairness captures the intuition that a decision is fair towards an individual if it is the same in (a) the actual world and (b) a counterfactual world where the individual belonged to a different demographic group. We demonstrate our framework on a real-world problem of fair prediction of success in law school.},
	language = {en},
	urldate = {2021-04-12},
	journal = {arXiv:1703.06856 [cs, stat]},
	author = {Kusner, Matt J. and Loftus, Joshua R. and Russell, Chris and Silva, Ricardo},
	month = mar,
	year = {2018},
	note = {arXiv: 1703.06856},
	keywords = {Computer Science - Computers and Society, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Kusner et al. - 2018 - Counterfactual Fairness.pdf:files/3450/Kusner et al. - 2018 - Counterfactual Fairness.pdf:application/pdf}
}

@article{kilbertus_avoiding_2018,
	title = {Avoiding {Discrimination} through {Causal} {Reasoning}},
	url = {http://arxiv.org/abs/1706.02744},
	abstract = {Recent work on fairness in machine learning has focused on various statistical discrimination criteria and how they trade off. Most of these criteria are observational: They depend only on the joint distribution of predictor, protected attribute, features, and outcome. While convenient to work with, observational criteria have severe inherent limitations that prevent them from resolving matters of fairness conclusively.},
	language = {en},
	urldate = {2021-04-12},
	journal = {arXiv:1706.02744 [cs, stat]},
	author = {Kilbertus, Niki and Rojas-Carulla, Mateo and Parascandolo, Giambattista and Hardt, Moritz and Janzing, Dominik and Schölkopf, Bernhard},
	month = jan,
	year = {2018},
	note = {arXiv: 1706.02744},
	keywords = {Computer Science - Computers and Society, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Kilbertus et al. - 2018 - Avoiding Discrimination through Causal Reasoning.pdf:files/3458/Kilbertus et al. - 2018 - Avoiding Discrimination through Causal Reasoning.pdf:application/pdf}
}

@article{von_kugelgen_fairness_2021,
	title = {On the {Fairness} of {Causal} {Algorithmic} {Recourse}},
	url = {http://arxiv.org/abs/2010.06529},
	abstract = {Many recent works have studied the problem of algorithmic fairness from the perspective of predictions. Instead, here we investigate the fairness of recourse actions recommended to individuals to recover from an unfavourable classiﬁcation. We propose two new fairness criteria at the group and individual level which—unlike prior work on equalising the average distance from the decision boundary across protected groups—explicitly account for the causal relationships between input features, thereby allowing us to capture downstream effects of recourse actions performed in the physical world. We explore how our criteria relate to others, such as counterfactual fairness, and show that fairness of recourse (both causal and non-causal) is complementary to fairness of prediction. We then investigate how to enforce fair causal recourse in the training of a classiﬁer. Finally, we discuss whether fairness violations in the data generating process revealed by our criteria may be better addressed by societal interventions as opposed to constraints on the classiﬁer.},
	language = {en},
	urldate = {2021-04-12},
	journal = {arXiv:2010.06529 [cs, stat]},
	author = {von Kügelgen, Julius and Karimi, Amir-Hossein and Bhatt, Umang and Valera, Isabel and Weller, Adrian and Schölkopf, Bernhard},
	month = feb,
	year = {2021},
	note = {arXiv: 2010.06529},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {von Kügelgen et al. - 2021 - On the Fairness of Causal Algorithmic Recourse.pdf:files/3459/von Kügelgen et al. - 2021 - On the Fairness of Causal Algorithmic Recourse.pdf:application/pdf}
}

@article{ness_integrating_2019,
	title = {Integrating {Markov} processes with structural causal modeling enables counterfactual inference in complex systems},
	url = {http://arxiv.org/abs/1911.02175},
	abstract = {This manuscript contributes a general and practical framework for casting a Markov process model of a system at equilibrium as a structural causal model, and carrying out counterfactual inference. Markov processes mathematically describe the mechanisms in the system, and predict the system’s equilibrium behavior upon intervention, but do not support counterfactual inference. In contrast, structural causal models support counterfactual inference, but do not identify the mechanisms. This manuscript leverages the beneﬁts of both approaches. We deﬁne the structural causal models in terms of the parameters and the equilibrium dynamics of the Markov process models, and counterfactual inference ﬂows from these settings. The proposed approach alleviates the identiﬁability drawback of the structural causal models, in that the counterfactual inference is consistent with the counterfactual trajectories simulated from the Markov process model. We showcase the beneﬁts of this framework in case studies of complex biomolecular systems with nonlinear dynamics. We illustrate that, in presence of Markov process model misspeciﬁcation, counterfactual inference leverages prior data, and therefore estimates the outcome of an intervention more accurately than a direct simulation.},
	language = {en},
	urldate = {2021-04-12},
	journal = {arXiv:1911.02175 [cs, q-bio, stat]},
	author = {Ness, Robert Osazuwa and Paneri, Kaushal and Vitek, Olga},
	month = nov,
	year = {2019},
	note = {arXiv: 1911.02175},
	keywords = {Computer Science - Machine Learning, Quantitative Biology - Molecular Networks, Statistics - Applications, Statistics - Machine Learning},
	file = {Ness et al. - 2019 - Integrating Markov processes with structural causa.pdf:files/3460/Ness et al. - 2019 - Integrating Markov processes with structural causa.pdf:application/pdf}
}

@article{karimi_algorithmic_2020,
	title = {Algorithmic {Recourse}: from {Counterfactual} {Explanations} to {Interventions}},
	shorttitle = {Algorithmic {Recourse}},
	url = {http://arxiv.org/abs/2002.06278},
	abstract = {As machine learning is increasingly used to inform consequential decision-making (e.g., pre-trial bail and loan approval), it becomes important to explain how the system arrived at its decision, and also suggest actions to achieve a favorable decision. Counterfactual explanations –“how the world would have (had) to be different for a desirable outcome to occur”– aim to satisfy these criteria. Existing works have primarily focused on designing algorithms to obtain counterfactual explanations for a wide range of settings. However, it has largely been overlooked that ultimately, one of the main objectives is to allow people to act rather than just understand. In layman’s terms, counterfactual explanations inform an individual where they need to get to, but not how to get there. In this work, we rely on causal reasoning to caution against the use of counterfactual explanations as a recommendable set of actions for recourse. Instead, we propose a shift of paradigm from recourse via nearest counterfactual explanations to recourse through minimal interventions, shifting the focus from explanations to interventions.},
	language = {en},
	urldate = {2021-04-12},
	journal = {arXiv:2002.06278 [cs, stat]},
	author = {Karimi, Amir-Hossein and Schölkopf, Bernhard and Valera, Isabel},
	month = oct,
	year = {2020},
	note = {arXiv: 2002.06278},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Karimi et al. - 2020 - Algorithmic Recourse from Counterfactual Explanat.pdf:files/3461/Karimi et al. - 2020 - Algorithmic Recourse from Counterfactual Explanat.pdf:application/pdf}
}

@article{hernan_invited_2015,
	title = {Invited {Commentary}: {Agent}-{Based} {Models} for {Causal} {Inference}--{Reweighting} {Data} and {Theory} in {Epidemiology}},
	volume = {181},
	issn = {0002-9262, 1476-6256},
	shorttitle = {Invited {Commentary}},
	url = {https://academic.oup.com/aje/article-lookup/doi/10.1093/aje/kwu272},
	doi = {10.1093/aje/kwu272},
	language = {en},
	number = {2},
	urldate = {2021-04-12},
	journal = {American Journal of Epidemiology},
	author = {Hernan, M. A.},
	month = jan,
	year = {2015},
	pages = {103--105},
	file = {Hernan - 2015 - Invited Commentary Agent-Based Models for Causal .pdf:files/3462/Hernan - 2015 - Invited Commentary Agent-Based Models for Causal .pdf:application/pdf}
}

@article{turbin2000adolescent,
  title={Adolescent cigarette smoking: Health-related behavior or normative transgression?},
  author={Turbin, Mark S and Jessor, Richard and Costa, Frances M},
  journal={Prevention Science},
  volume={1},
  number={3},
  pages={115--124},
  year={2000},
  publisher={Springer}
}

@article{kalisch2012causal,
  title={Causal inference using graphical models with the R package pcalg},
  author={Kalisch, Markus and M{\"a}chler, Martin and Colombo, Diego and Maathuis, Marloes H and B{\"u}hlmann, Peter},
  journal={Journal of Statistical Software},
  volume={47},
  number={11},
  pages={1--26},
  year={2012},
  publisher={American Statistical Association}
}

@article{judea2010introduction,
  title={An introduction to causal inference},
  author={Pearl, Judea},
  journal={The International Journal of Biostatistics},
  volume={6},
  number={2},
  pages={1--62},
  year={2010},
  publisher={De Gruyter}
}

@inproceedings{forre2020causal,
  title={Causal calculus in the presence of cycles, latent confounders and selection bias},
  author={Forr{\'e}, Patrick and Mooij, Joris M},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={71--80},
  year={2020},
  organization={PMLR}
}

@article{spirtes2010introduction,
  title={Introduction to causal inference.},
  author={Spirtes, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={5},
  year={2010}
}

@article{hirano2001estimation,
  title={Estimation of causal effects using propensity score weighting: An application to data on right heart catheterization},
  author={Hirano, Keisuke and Imbens, Guido W},
  journal={Health Services and Outcomes research methodology},
  volume={2},
  number={3},
  pages={259--278},
  year={2001},
  publisher={Springer}
}


@incollection{bollen2013eight,
  title={Eight myths about causality and structural equation models},
  author={Bollen, Kenneth A and Pearl, Judea},
  booktitle={Handbook of causal analysis for social research},
  pages={301--328},
  year={2013},
  publisher={Springer}
}

@incollection{rosenbaum2002overt,
  title={Overt bias in observational studies},
  author={Rosenbaum, Paul R},
  booktitle={Observational studies},
  pages={71--104},
  year={2002},
  publisher={Springer}
}

@article{pearl2009myth,
  title={Myth, confusion, and science in causal analysis},
  author={Pearl, Judea},
  year={2009}
}

@article{rubin2007design,
  title={The design versus the analysis of observational studies for causal effects: parallels with the design of randomized trials},
  author={Rubin, Donald B},
  journal={Statistics in medicine},
  volume={26},
  number={1},
  pages={20--36},
  year={2007},
  publisher={Wiley Online Library}
}
