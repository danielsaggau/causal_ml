---
title: "A Gentle Introduction into Structural Causal Models"
author: 
- Daniel Saggau $\boldsymbol{\cdot}$ `daniel.saggau@campus.lmu.de`
- Department of Statistics, Ludwig Maximilian University Munich, Germany
date: "June 2021"
output: 
  pdf_document:
        number_sections: yes
        fig_caption: yes
link-citations: yes
linkcolor: blue
fontsize: 12
fontfamily: mathpazo 
linestretch: 1.5
citation_package: --biblatex
bibliography: [ref.bib]
nocite: '@*'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Abstract** The interest in understanding relationships of variables beyond co-occurrence has increased the popularity of causal modelling. 
Probabilistic specifications cast a model based on conditional probabilities. 
SCMs cast a model based on  asymmetric assignments and extend probabilistic models by specifying the entire data generating process rather than solely utilizing conditional probabilities.
A SCM is build on a number of different assumptions namely the independence of noise, autonomy of mechanisms, causal sufficiency and the causal markov condition.
I also discuss the role of time in causality and how differential equations enable us to model SCMs similar to a mechanical mdoel.
Another difference between thes SCM and other model specifications is the ability  of SCMs to address different queries such as *predictions*, *interventions* and *counterfactuals*. 
These queries are part of Pearl's causal hierarchy (2009).
Pearl matches these queries with their respective actions namely *observing*, *doing* and *imagining*. 
I compare the feasibility of addressing these queries.
The insights of this paper can be used as a baseline for subsequent research on structural causal models.

\newpage
\hypersetup{linkcolor=black}
\tableofcontents
\newpage

\hypersetup{linkcolor=blue}

# Introduction 

For many research problems, we want to understand the relationship between variables beyond co-occurrence.
The most popular causal model is the structural causal model or in short SCM.
The SCM is an expressive simulator to estimate causal relationships, accounting for latent factors. 
Latent factors are unobserved factors [@pearl2009causality].
SCMs entail endogenous and exogenous variables. 
Exogenous variables should not be confused with latent variables.
For reference, @peters_elements_2017 define endogenous and exogenous as follows: *Endogeneous variables are those that the modeler tries to understand, while exogenous ones are determined by factors outside the model, and are taken as given.*
The basis of these SCMs is a set of equations, or more precisely assignments, providing functions to derive the conditional probabilities for our model [@hardtrecht].
These assignments describe our variables in our model.
Compared to probabilistic models, where we only specify conditional probabilities, the SCM actually enables the combination of different sources of knowledge.
In association based learning and typical statistical learning we only model based on observational data and conditional probabilities. 
Conditional probabilities alone, cannot represent latent variables because there is no conditional probability in our observational data for unobserved variables [@pearl2009causality].


To accommodate existing literature, this paper provides a gentle introduction to SCMs, focusing on the underlying assumptions we make when building a structural causal model.
Specifically, this paper focuses on the independence of noise, independence of mechanisms, causal sufficiency, the role of time and the causal markov condition.
Additionally, this paper provides an overview of various other statistical and causal methods within the grand scheme of pearls causal hierachy.
I accommodate this outlook with various considerations for the usage of SCMs. 
The aim of this paper is to provide an intuitive understanding of different concepts within causality using elements from core literature on causality. 

The rest of the paper is structured as follows:
 

 

# Assumptions in Structural Causal Models 

The SCM is the non-parametric counterpart to structural equation models.
Researchers on SCMs tried to distance themselves from common practices for structural equation models [@pearl2009causality; @peters_elements_2017].
The geneticist and statistican Sewall Wright introduced the first ancestor of the SCM, the path analysis [@pearl2009causality; @tarka2018overview].
Path analysis now falls into the broader class of structural equation models.
Path analysis is a structural equation model with one variable per indicator.


## Mathematical Components

The structural causal model consists of a set of equations.
These equations are asymmetric assignments, because they are not bi-directional.
We cannot change the sides of the equation as one can do with regular equations [@pearl2012causal].
[@peters_elements_2017] define a SCM as follows: 

**Definition 1:** Structural Causal Model: 

*An SCM* $\mathbb{C}$ *with graph* $C \rightarrow E$ *consists of two assignments*

$$
\begin{array}{l}
C:=N_{C} \\
E:=f_{E}\left(C, N_{E}\right)
\end{array}
$$
*where* $N_{F} \perp \!\!\! \perp N_{C}$ *that is* $N_{F}$ *is independent of* $N_{C}$

In their definition, C is the cause and E is the effect.

We can set up an epidemiological example with three variables, looking at the impact of problem behavior and genetic code on lung cancer. 
Problem behavior is a latent variable, but we can use observational data to characterize problem behavior.
One example of problem behavior is smoking.
Henceforth,to estimate problem behaviour, we can for instance ask participants how frequently they smoke.
For genetic code, we could look for specific genes and and examine whether the presence of specific genes has an impact on getting cancer. 
As we can see, these functions are driven by underlying latent variables.
These latent factors are the foundation of the structural causal model [@hardtrecht; @pearl2009causality; @pearl2012causal].

\begin{equation}
S:= f_S(U_S)
\end{equation}
\begin{equation}
G:= f_G(U_G)
\end{equation}
\begin{equation}
C:= f_C(S,G,U_C)
\end{equation}

where: 
$\{S\}$ - Frequency of smoking
$\{G\}$ - Presence of specific genes
$\{C\}$ - Lung cancer

Every structural causal model contains an underlying graphical model [@hardtrecht]. 
This is one important feature that differentiates SCMs from other frameworks^[e.g. the Potential Outcome framework[@pearl2009causality]]. 

[@pearl2009causality] describes the SCM a process based tool, because it enables researchers to reflect on their underlying assumptions. 
The SCM requires more assumptions and thought.
Even for a very minimalisitic SCM, we need to define an admissible set of variables, ensure the random noise terms are independent and corroborate that the underlying mechanisms are autonomous. 
By being forced to think about all these steps, SCMs help to avoid poorly specified probabilistic specifications. 
Various research has pointed out examples where modeling without DAGs lead to severe mistakes: 
@hirano2001estimation suggest a method for covariate selection that according to @pearl2009myth favours bias-enhancing features in the propensity score.
Further @bollen2013eight (2013) argue that @rosenbaum2002overt and @rubin2007design falsely declared that 'there is no reason to avoid adjustment for a variable describing subjects before treatment'.

## Independence of Noise and Mechanism

**Definition:** Independence 
*The causal generative process of a system’s variables is composed of autonomous modules that do not inform or influence each other.*
*In the probabilistic case, this means that the conditional distribution of each variable given its causes (i.e., its mechanism) does not inform or influence the other conditional distributions*,
*In case we have only two variables, this reduces to an independence between the cause distribution and the mechanism producing the effect distribution* [@peters_elements_2017].

If we specify the causal structure correctly: 

- possible to undertake local intervention -> change f(smoking), regardless of f(cancer|smoking)
- these components are autonomous objects -> set of autonomous assignments

**Independence of Noise:**  

The way we view noise in SCMs differs from the classical view in regression analysis.
Therefore, I will briefly clarify essential differences. 
Noise variables are our latent variables which are the parent nodes of our child nodes of interest [@hardtrecht].
In classical regression analysis, such as an ordinary least squares regression, we employ the Gauss Markov Assumptions. 
The exogeneity assumption, one of the five Gauss Markov Assumptions, suggests that the error terms are uncorrelated with our features [@wooldridge2010econometric].
For the SCM, the error terms are driving our features and a pivotal component of the model specification [@hardtrecht].
To ensure that we are correctly specifying mechanisms and our underlying model structure, one needs to ensure independence of these noise terms. 
As mentioned in the definition for SCMs, we would mathematical notate this independence as follows:

$N_{F} \perp \!\!\! \perp N_{C}$ 

Scholarship in causality established the causal sufficiency condition:

**Definition:** Causal Sufficiency

*A set of variables X is usually said to be causally sufficient if there is no hidden common cause $C \notin X$ that is causing more than one variable in X* [@peters_elements_2017; @spirtes2010introduction] 

By ensuring that this condition holds, we can easier disentangle underlying common causes, avoiding a violation of the independence of our noise terms.
Independence of noise is one form of causal sufficiency [@peters_elements_2017].

There are two related dimensions to consider namely the informational aspect of independence  and implications for  modularity. 
If the independence conditions holds, and the cause and effect variables are independent, the cause and effect variable do not contain information about each other. 
Modularity [@pearl2009causality] describes the advantage of being able to treat these variables as distinct modules.
This means, even if we have a change in one variable (cause or effect), we can disentangle our variable as unique modular components.
Especially looking at machine learning, domain shift and covariate shift are problematic for classical tools. [@peters_elements_2017]
By using these independence assumptions in SCMs, we can accommodate these settings.

Looking at our smoking example:


$$
P(Cancer|Smoking)=P(Smoking|Cancer) \times P(Cancer)
$$

**Markov Condition** 

@pearl2009causality defines the markov condition as follows: 

**Definition:** Causal Markov Condition

*Every Markovian causal model M induces a distribution P(x1,…, xn) that satisfies the parental Markov condition relative the causal diagram G associated with M; that is, each variable Xi is independent of all its nondescendants, given its parents PAi in G.*


**Mechanism**

\begin{equation}
\begin{aligned}
p(a, t) &=p(a \mid t) p(t) \\
&=p(t \mid a) p(a)
\end{aligned}
\end{equation}


\begin{equation}
p^{\mathrm{o}}(a, t)=p(t \mid a) p^{\mathrm{o}}(a) \text { and } p^{\mathrm{s}}(a, t)=p(t \mid a) p^{\mathrm{s}}(a) .
\end{equation}

$$
\begin{array}{l}
P_{x}(v)=\prod_{\left\{i \mid V_{i} \notin X\right\}} P\left(v_{i} \mid p a_{i}\right)\\
\text { for all } \boldsymbol{v} \text { consistent with } x
\end{array}
$$



# Directed Acyclic Graphs 

The most popular graphical model is the directed acyclic graph or in short DAG.
A causal graph for a SCM contains endogenous and exogenous variables. 
A DAG entails nodes and edges. 

Nodes represent our different variables. 
Edges depict the assignment equations. 
All edges are directed in the DAG.
An acyclic graph has no roots that cause itself (directly and indirectly) [@morgan_winship_2014].

This acyclic structure is important for the conditional probabilities [@forre2020causal].

may not find unique solution if cyclic in equilbrium [@peters_elements_2017]

Variables have incoming paths from their parent nodes. 

These DAGs can be built on theory.
Another way to determine the DAG structure is using observational data. 
One of the more prominent algorithm to estimate the underlying dag structure is the pc-algorithm [@kalisch2012causal] . 

```{tikz,fig.cap="Structural Causal Model" ,fig.align="center", echo =F}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
  \begin{tikzpicture}[
    sharp corners=2pt,
    inner sep=6pt,
    node distance=2cm,
    >=latex]
\tikzstyle{my node}=[draw, shape = circle, minimum height=1cm,minimum width=1cm]
\tikzstyle{latent}=[draw, shape = rectangle, minimum height=1cm,minimum width=1cm]
\node[my node, fill=gray!30] (S){S};
\node[latent,left of=S](US){$U_S$};
\node[my node, fill=gray!30] at ($(S)!0.5!(S)-(0pt,1.5cm)$) (G) {G};
\node[my node,right = 1 cm of G, fill=gray!30](C){C};
\node[latent,left = 1cm of G](UG){$U_G$};
\node[latent,right = 1cm of S](UC){$U_C$};
\draw[->] (US) -- (S);
\draw[->] (UG) -- (G);
\draw[->] (UC) -- (C);
\draw[->] (S) -- (C);
\draw[->] (G) -- (C);
\end{tikzpicture}
```

Graphical models developed a mathematical langauge to assess certain conditions. 



We can create graphical models based on various algorithms.

We can obtain a graphical model based on (a single) observational dataset through conditional independence testing.
The graphical approach to recover a graph from an observaational dataset requires two assumptions namely jointly independent noise terms and faithfulness. 
Intuitively speaking, this method examines how noise spreads [@peters_elements_2017]. 
Two other methods are ICM^[The intuition here is that the noise terms cultivate the footprint of the assignments. For more information see: @shajarisales2015telling] and using an additive noise model^[This method uses regression and conditional independence testing to disentangle graphical structures. For further information see @mooij2016distinguishing]. 


# SCMs and Time 

largely ingore time 

time in mechanical modeling crucial [@peters_elements_2017].

- Time in Social Sciences: Often Vague 
- Time in Physical Sciences: Mechanical via **Differential equations** 
- dependence on prior time point and change in time contribute to the value at time point

Initial Value: 
$$
\mathbf{x}\left(t_{0}\right)=\mathbf{x}_{0}
$$

Derivative of function x with respect to time t: 

$$
\frac{d \mathbf{x}}{d t}=f(\mathbf{x}), \mathbf{x} \in \mathbb{R}^{d}
$$

Value of Function at time t + dt: 

$$
\mathbf{x}(t+d t)=\mathbf{x}(t)+d t \cdot f(\mathbf{x}(t))
$$


[@peters_elements_2017] provide a taxonomy of different methods (see table 1) 


$$\text{Table 1 Source: Peters et al. (2017) , Modelling Taxonomy}$$
$$
\begin{array}{|l|l|l|l|l|}
\hline \text { model } & \begin{array}{l}
\text { IID setting }
\end{array} & \begin{array}{l}
\text { changing } \\
\text { distributions } 
\end{array} & \begin{array}{c}
\text { counter- } \\
\text { factual } \\
\text { questions }
\end{array} & \begin{array}{l}
\text { physical } \\
\text { insight }
\end{array} \\
\hline \begin{array}{l}
\text { mechanistic } \\
\text { model }
\end{array} & \mathrm{Y} & \mathrm{Y} & \mathrm{Y} & \mathrm{Y} \\
\hline \begin{array}{l}
\text { structural } \\
\text { causal model }
\end{array} & \mathrm{Y} & \mathrm{Y} & \mathrm{Y} & \mathrm{N} \\
\hline \begin{array}{l}
\text { causal } \\
\text { graphical } \\
\text { model }
\end{array} & \mathrm{Y} & \mathrm{Y} & \mathrm{N} & \mathrm{N} \\
\hline \begin{array}{l}
\text { statistical } \\
\text { model }
\end{array} & \mathrm{Y} & \mathrm{N} & \mathrm{N} & \mathrm{N} \\
\hline
\end{array}
$$

In the table we can see that traditional statistical models fair well in IID settings, where our observations are independent and identically distributed.
But once we encounter a changing distribution such as an covariate shift or a domain shift, these statistical models are not suitable anymore.
Statistical models are also unable to answer any counterfactual questions about hypothetical settings outside of our observational data and are unable to provide physical insights because we do not model time as an explicity. 
Causal graphical models are able to deal with changing distributions and fair well in the IID setting. 
Nevertheless, they are also unable to answer counterfactual questions on its own and cannot provide physical insights. 
SCMs are able to deal with the first three queries, but largely ignore time.
By commonly making assumptions such as that the effect is acyclic, SCMs simplify time and treat focus on equilbrium states.
The mechanistic view, where we model time as an explicit factor, enables us to answer all those queries. 
Note that the growing complexity makes it very challenging to implement but relevant for natural sciences where time is pivotal to disentangle relationships [@mooij2013ordinary; @peters_elements_2017]. 

# Pearl's Causal Hierachy 

Pearl [@bareinboim2020pearl; @pearl2009causality] introduced the hierachy of causation to categorize different statistical and causal tools. 
The hierarchy of causation contains (see table 1) three levels, where the high methods on the hierarchy, the more information the method requires.
This section discusses each of these methods and their respective advantages.

$$\text{Table 2 Source: Pearl (2009) , Hierarchy of Causation}$$ 
\footnotesize

|Method          | Action |  Example | Usage | 
|------------------|-------------|--------------------|-------------------|
| Association $P(a|b)$               | Co-occurrence             | What happened...               |(Un-)Supervised ML, BN, Reg.  
| Intervention $P(a|do(b),c)$       | Do-manipulation           | What happens if ...            |CBN,MDP,RL    
| Counterfactual $P(a_b|a`,b`)$     | Hypotheticals   | What would have happened if...           | SCM ,PO            

\normalsize

## Association:

The first level, association, requires the least information.
Association based methods are most prevalent and contain the largest class of methods.
Standard statistical tools such as regression analysis, supervised and unsupervsied learning and bayesian networks all fall into this category.[@bareinboim2020pearl]
The underlying action for association is co-occurence.
As prominently criticized by @bender2021dangers, this reduces the number of questions we can answer, because methods are heavily dependent on the observational data. 
In the context of deep learning and the advancement of natural language processing, @bender2021dangers suggest that many association-based methods results in stochastic parrots as opposed to natural langauge understanding.

Association-based methods ignore external changes outside of our data.
The interventional distribution has information on these external changes.
Note, that the intervention distribution is only defined in high order methods. 

Reiterating our lung cancer example, the full joint distribution looks as follows: 

$P(c,s,g)= P(s) \times P(c|s,g) \times P(g)$ 

If there are any changes in our distribution, e.g. smoking changes its distribution from $s$ to $s_{new}$ we are unable to accomodate these changes [@peters_elements_2017].
Association-based methods are not equipped to accomodate such modifications. 


There are ways to also graphically depict associational models. 
One example is the bayesian network, which uses conditional probabilities instead of functions to describe the relationship between variables [@pearl2009causality]
In the probabilistic representation, we ignore latent factors [@creager; @pearl2009causality]. 

```{tikz,fig.cap="Probabilistic Model" ,fig.align="center", echo =F}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
  \begin{tikzpicture}[
    sharp corners=2pt,
    inner sep=6pt,
    node distance=2cm,
    >=latex]
\tikzstyle{my node}=[draw, shape = circle, minimum height=1cm,minimum width=1cm]
\tikzstyle{latent}=[draw, shape = rectangle, minimum height=1cm,minimum width=1cm]
\node[my node, fill=gray!30] (p){S};
\node[my node, fill=gray!30] at ($(p)!0.5!(p)-(0pt,1.5cm)$) (G) {G};
\node[my node,right = 1 cm of G, fill=gray!30](C){C};
\draw[->] (p) -- (C);
\draw[->] (G) -- (C);
\end{tikzpicture}
```

While in this simple 3 feature case, the graphical illustration is rather straight forward. 
But especially in a high dimensional space, the graphical models become convoluted.
Henceforth, finding the correct specification without reconsidering all modelling assumptions can led to mistakes as discussed in section 2. 

## Intervention:

Intervention deals with questions like 'what happens if'. 
E.g. in our smoking example, we could look at e.g. 'what happens if people smoke less?' or, 'what happens if people smoke more?'.
This higher order methods opens many different applications and is predominately possible in causal bayesian networks, reinforcement learning or markov decision processes.
For interventions, we can use @pearl2009causality do-calculus.
The do-calculus enables us to study the manipulation of parent nodes.
Instead of merely seeing the co-occurence of variables, we can actively manipulate the conditional distribution of one variable.
Commonly, one could use this method to evaluate different policies [@creager].
In our cancer example one can actively set the smoking behavior to a fixed value or a different conditional probability.
The post intervention joint distribution would look as follows: 
$P_{S=s}(c,g)= P(c|S=s,g) \times P(g)$ 
where $S=s$ is the new probability or atomic value.
There are various types of intervention.
I will illustrate atomic intervention and policy intervention based on our smoking example.

In **atomic intervention,** we set a variable to a constant value.
As one can see in figure 3, c is constant that is not dependent on the latent factor, because in atomic intervention we do not derive the value of c based on the function S. 

```{tikz,fig.cap="Atomic Intervention" ,fig.align="center", echo =F}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
  \begin{tikzpicture}[
    sharp corners=2pt,
    inner sep=6pt,
    node distance=2cm,
    >=latex]
\tikzstyle{my node}=[draw, shape = circle, minimum height=1cm,minimum width=1cm]
\tikzstyle{latent}=[draw, shape = rectangle, minimum height=1cm,minimum width=1cm]
\node[my node, fill=gray!10] (p){c};
\node[my node, fill=gray!30] at ($(p)!0.5!(p)-(0pt,1.5cm)$) (G) {G};
\node[my node,right = 1 cm of G, fill=gray!30](C){C};
\node[latent,left = 1cm of G](UG){$U_G$};
\node[latent,right = 1cm of p](UC){$U_C$};
\draw[->] (UG) -- (G);
\draw[->] (UC) -- (C);
\draw[->] (p) -- (C);
\draw[->] (G) -- (C);
\end{tikzpicture}
```

Further, in mathematical notation the model would change as follows:

\begin{equation}
S:= s
\end{equation}
\begin{equation}
G:= f_G(U_G)
\end{equation}
\begin{equation}
C:= f_C(S,G,U_C)
\end{equation}

In **policy intervention** (see figure 4) we specify a different conditional probability $(S=s)$ for an equation.
We can derive s from S, because we include information on the intervention distribution. 
This information cannot be obtained, if we directly specify our model as conditional probabilities.

```{tikz,fig.cap="Policy Intervention" ,fig.align="center", echo =F}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
  \begin{tikzpicture}[
    sharp corners=2pt,
    inner sep=6pt,
    node distance=2cm,
    >=latex]
\tikzstyle{my node}=[draw, shape = circle, minimum height=1cm,minimum width=1cm]
\tikzstyle{latent}=[draw, shape = rectangle, minimum height=1cm,minimum width=1cm]
\node[my node, fill=gray!10] (p){s};
\node[latent,left of=p](US){$U_S$};
\node[my node, fill=gray!30] at ($(p)!0.5!(p)-(0pt,1.5cm)$) (G) {G};
\node[my node,right = 1 cm of G, fill=gray!30](C){C};
\node[latent,left = 1cm of G](UG){$U_G$};
\node[latent,right = 1cm of p](UC){$U_C$};
\draw[->] (US) -- (p);
\draw[->] (UG) -- (G);
\draw[->] (UC) -- (C);
\draw[->] (p) -- (C);
\draw[->] (G) -- (C);
\end{tikzpicture}
```

where $s$ is our new conditional probability. 

One way of the most prominent ways to estimate casual effects of our treatment is the average treatment effect.
The average treatment effect looks at the difference between treatment and control group.
For the case of simplicity in our example, we want to look at whether smoking at all has an impact on lung cancer.
Mathematically, this could as follows: 

\begin{equation}
f(C|S=1) - f(C|S=0)
\end{equation}

where $S = 1$ means the participant smokes and $S=0$ means the participant does not smoke.
Furthermore, it is crucial that we hold all other factors constant so looking at our example, we would compare people with the same genetic features to truely isolate the effect of smoking.
The ATE is a population level effect [@hardtrecht].

**Confounders**

Confounding is the circumstance where the observational information (conditional probabilities in our data) and intervention are different.
Essentially, we want to express our do-intervention based on conditional probabilities, but have no direct information in our data.
To still estimate a conditional probability, we can use a mixture of existing conditional probabilities and estimate the desired probability based on the adjustment formula.
For further information, see  [@barocas].

## Counterfactuals

Counterfactuals deal with hypothetical situations. 
Philosophically speaking, we interpret these outcomes as actual outcomes^[In other frameworks such as the Potential outcome framework we interpret them as potential outcomes rather than true outcomes [@hardtrecht]].
The two most prominent models that can obtain counterfactuals are the structural causal model and the potential outcome framework. 
This section focuses on counterfactuals in structural causal models. 
For information on how to obtain counterfactuals in the potential outcome framework, see @cunningham2021causal. 

We can describe the process as follows:

(a) Abduction: Cast probability $P(u)$ as conditional probability $P(u|\epsilon)$ 
(b) Action: Exchange $(X = x)$ 
(c) Prediction: Compute $(Y = y)$

**Stable Unit Treatment Value Assumption {SUTVA}** 'The treatment that one unit receives does not change the effect of treatment for any other unit.'
**Consistency** The outcome Y agrees with the potential outcome corresponding to the treatment indicator.' 
**Ignorability** The potential outcomes are conditionally independent of treatment given some set of de-confounding variables. 
As suggested by [@hardtrecht], this condition ensures that we are dealing with a perfect randomized controlled trial. 
The first two conditions hold for counterfactuals in structural causal models. 
The third condition is an untestable assumption.
Due to the backdoor criterion, we can nevertheless verify, that our model specification is consistent with this assumption [@hardtrecht].

## Considerations

Structural causal models are data driven models [@hernan_invited_2015]. 
There is a dependence on data quality.
Evaluating different sources of information into causal models accordingly is an open problem in causal modelling [@spirtes2010introduction].
Henceforth, if our insights based on data are limited, or perhaps we are not really able to clearly define function relationships beyond conditional probabilities, structural causal models can be problematic.
Furthermore, sometimes association-based knowledge is sufficient.
inevitably, the entry barrier to higher order causal models is higher in terms of required knowledge. 
Not every situation accomodates these conditions. 

Nevertheless, especially in a situation where we have high-stake repercussions based on our model, causal modelling has been a complementary tool.
When dealing with policy implementations, that might be controversial or unethical in the real world, simulations are pivotal.
Recently, research has fairness has adopted various concepts and developed new characteristics such as counterfactual fairness [@kusner_counterfactual_2018].


# Conclusion 

Structural causal models are flexible simulators to disentangle causality for manifold different queries such as interventions and counterfactuals.
We make a number of different assumptions when building a structural causal model.
The most important assumption is the indepedence of mechanisms and independence of noise terms which are the core of our simulation. 

There are many advantages of structural causal models:
(1) We are able to model latent factors forcing us to reconsider existing assumptions about the relationship in our data.
(2) Further, we get a underlying graphical representation including a mathematical language for this graphical systems to test causal assumptions that are otherwise untestable.
(3) Additionally, one is able to model queries beyond mere association going as far as dealing with hyptoethical situations. 

Apart from the assumptions, causal graphics can help reseachers avoiding mistakes.
To determine this causal graph, we can use conditional independence testing and assess assumptions about faithfulness and jointly independent noise terms. 

Looking at the causal hierachy, structural causal modelling enables us to compute interventions efficiently given certain condition hold. 
These conditions defintely not always hold true in every instance.
The entry barriers to causal modeling is high and in involves considerable investment in terms of data and time.

\newpage 

# References

<div id="refs"></div>
\newpage

