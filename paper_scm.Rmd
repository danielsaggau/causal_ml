---
title: "A Gentle Introduction into Structural Causal Models"
author: 
- Daniel Saggau $\boldsymbol{\cdot}$ `daniel.saggau@campus.lmu.de`
- Department of Statistics, Ludwig Maximilian University Munich, Germany
date: "June 2021"
output: 
  pdf_document:
        number_sections: yes
        fig_caption: yes
link-citations: yes
linkcolor: blue
fontsize: 12
fontfamily: mathpazo 
linestretch: 1.5
citation_package: --biblatex
bibliography: [ref.bib]
nocite: '@*'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Abstract** The interest in understanding relationships of variables beyond co-occurrence has increased the popularity of causal modelling. Probabilistic specifications cast a model based on conditional probabilities. SCMs cast a model based on  assymetric assignments and extend probabilistic models by specifying the entire data generating process rather than solely utilizing conditional probabilities. 
Another difference between these models is their ability to address different queries such as *predictions*, *interventions* and *counterfactuals*. 
These queries are part of Pearl's causal hierarchy (2009).
Pearl matches these queries with their respective actions namely *observing*, *doing* and *imagining*. 
I compare the feasibility of addressing these queries and undertaking respective actions for both specifications.
To contextualize SCMs within the field of causality, I also discuss the role of time in causality.
This paper uses various directed acyclic graphs to highlight the differences in these modelling approaches.
The insights of this paper can be used as a baseline for subsequent research on structural causal models.

\newpage
\hypersetup{linkcolor=black}
\tableofcontents
\newpage

\hypersetup{linkcolor=blue}

# Introduction 

For many research problems, we want to understand the relationship between variables beyond co-occurrence.
The most popular causal model is the structural causal model or in short SCM.
The SCM is the non-parametric counterpart to structural equation models.
Researchers on structural causal models tried to distance themselves from common practices for structural equation models [@pearl2009causality; @peters_elements_2017].
The geneticist and statistican Sewall Wright introduced the first ancestor of the SCM, the path analysis [@pearl2009causality].
Path analysis now falls into the broader class of structural equation models.
Path analysis is a structural equation model with one variable per indicator.

The SCM is an expressive simulator to estimate causal relationships, accounting for latent factors. 
Latent factors are unobserved factors [@pearl2009causality].
SCMs entail endogenous and exogenous variables. 
Exogenous variables should not be confused with latent variables.
For reference, @peters_elements_2017 define endogenous and exogenous as follows: *Endogeneous variables are those that the modeler tries to understand, while exogenous ones are determined by factors outside the model, and are taken as given.*
The basis of these SCMs is a set of equations, or more precisely assignments, providing functions to derive the conditional probabilities for our model [@hardtrecht].
These assignments describe our variables in our model.
Compared to probabilistic models, where we only specify conditional probabilities, the SCM actually enables the combination of latent variables and observational data.
Conditional probabilities cannot represent latent variables because there is no conditional probability in our observational data for unobserved variables [@pearl2009causality].

The aim of this paper is to provide a brief and intuitive introduction to SCMs. 


Section 2 introduces the assumptions in causal modelling
Section 3 addresses Pearls Causal Hierachy.
Section 4 provides a brief introduction into graphical models.
Section 5 focuses on the intersection of SCMs and the perception of time. 


# Assumptions in Structural Causal Models 

The structural causal model consists of a set of equations.
These equations are asymmetric assignments, because they are not bi-directional.
We cannot change the sides of the equation as one can do with regular equations [@pearl2012causal].
[@peters_elements_2017] define a SCM as follows: 

**Definition 1:** Structural Causal Model: 

*An SCM* $\mathbb{C}$ *with graph* $C \rightarrow E$ *consists of two assignments*

$$
\begin{array}{l}
C:=N_{C} \\
E:=f_{E}\left(C, N_{E}\right)
\end{array}
$$
*where* $N_{F} \perp \!\!\! \perp N_{C}$ *that is* $N_{F}$ *is independent of* $N_{C}$

In their definition, C is the cause and E is the effect.




We can set up an epidemiological example with three variables, looking at the impact of problem behavior and genetic code on lung cancer. 
Problem behavior is a latent variable, but we can use observational data to characterize problem behavior.
One example of problem behavior is smoking.
Henceforth,to estimate problem behaviour, we can for instance ask participants how frequently they smoke.
For genetic code, we could look for specific genes and and examine whether the presence of specific genes has an impact on getting cancer. 
As we can see, these functions are driven by underlying latent variables.
These latent factors are the foundation of the structural causal model [@hardtrecht; @pearl2009causality; @pearl2012causal].

\begin{equation}
S:= f_S(U_S)
\end{equation}
\begin{equation}
G:= f_G(U_G)
\end{equation}
\begin{equation}
C:= f_C(S,G,U_C)
\end{equation}

where: 
$\{S\}$ - Frequency of smoking
$\{G\}$ - Presence of specific genes
$\{C\}$ - Lung cancer

Every structural causal model contains an underlying graphical model [@hardtrecht]. 
This is one important feature that differentiates SCMs from other frameworks^[e.g. the Potential Outcome framework[@pearl2009causality]]. 

[@pearl2009causality] describes the SCM a process based tool, because it enables researchers to reflect on their underlying assumptions. 
The SCM requires more assumptions and thought because we actually need to define an admissible set of variables, ensure they are independent and ensure that the underlying factors do not correlate. By being forced to think about all these steps, SCMs help to avoid poorly specified probabilistic specifications. 
Various research has pointed outexamples where modeling without DAGs lead to severe mistakes: 
@hirano2001estimation suggest a method for covariate selection that according to @pearl2009myth favours bias-enhancing features in the propensity score.
Further @bollen2013eight (2013) argue that @rosenbaum2002overt and @rubin2007design falsely declared that 'there is no reason to avoid adjustment for a variable describing subjects before treatment'.


We can craete graphical models based on various different algorithms.

The most popular graphical model is the directed acyclic graph or in short DAG.
A causal graph for a SCM contains endogenous and exogenous variables. 
A DAG entails nodes and edges. 

Nodes represent our different variables. 
Edges depict the assignment equations. 
All edges are directed in the DAG.
An acyclic graph has no roots that cause itself (directly and indirectly) [@morgan_winship_2014].

This acyclic structure is important for the conditional probabilities [@forre2020causal].

may not find unique solution if cyclic in equilbrium [@peters_elements_2017]

Variables have incoming paths from their parent nodes. 

These DAGs can be built on theory.
Another way to determine the DAG structure is using observational data. 
One of the more prominent algorithm to estimate the underlying dag structure is the pc-algorithm [@kalisch2012causal] . 

```{tikz,fig.cap="Structural Causal Model" ,fig.align="center", echo =F}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
  \begin{tikzpicture}[
    sharp corners=2pt,
    inner sep=6pt,
    node distance=2cm,
    >=latex]
\tikzstyle{my node}=[draw, shape = circle, minimum height=1cm,minimum width=1cm]
\tikzstyle{latent}=[draw, shape = rectangle, minimum height=1cm,minimum width=1cm]
\node[my node, fill=gray!30] (S){S};
\node[latent,left of=S](US){$U_S$};
\node[my node, fill=gray!30] at ($(S)!0.5!(S)-(0pt,1.5cm)$) (G) {G};
\node[my node,right = 1 cm of G, fill=gray!30](C){C};
\node[latent,left = 1cm of G](UG){$U_G$};
\node[latent,right = 1cm of S](UC){$U_C$};
\draw[->] (US) -- (S);
\draw[->] (UG) -- (G);
\draw[->] (UC) -- (C);
\draw[->] (S) -- (C);
\draw[->] (G) -- (C);
\end{tikzpicture}
```

Graphical models developed a mathematical langauge to assess certain conditions. 
One pivotal feature is the d-separation [@judea2010introduction]:

**Definition 2** ( $d$ -separation) A set $S$ of nodes is said to block a path $p$ if either (i) $p$ contains at least one arrow-emitting node that is in $S$, or $($ ii $)$ p contains at least one collision node that is outside $S$ and has no descendant in $S .$ 
If $S$ blocks all paths from $X$ to $Y$, it is said to " $d$ -separate $X$ and $Y, "$ and then, $X$ and $Y$ are independent given $S$, written $X \perp \!\!\! \perp Y \mid S .$

Select subset of variables with backdoor criterion: 



## Independence

**Definition:** Independence 
*The causal generative process of a system’s variables is composed of autonomous modules that do not inform or influence each other.*
*In the probabilistic case, this means that the conditional distribution of each variable given its causes (i.e., its mechanism) does not inform or influence the other conditional distributions*,
*In case we have only two variables, this reduces to an independence between the cause distribution and the mechanism producing the effect distribution* [@peters_elements_2017].

If we specify the causal structure correctly: 

(a) possible to undertake local intervention -> change f(x), regardless of f(y|x)
(b) these components are autonomous objects -> set of autonomous equations 


Independence of Noise, 

Noise independent so problematic behaviour and genetic code should be independent. 

**Mechanism**

\begin{equation}
\begin{aligned}
p(a, t) &=p(a \mid t) p(t) \\
&=p(t \mid a) p(a)
\end{aligned}
\end{equation}


\begin{equation}
p^{\mathrm{o}}(a, t)=p(t \mid a) p^{\mathrm{o}}(a) \text { and } p^{\mathrm{s}}(a, t)=p(t \mid a) p^{\mathrm{s}}(a) .
\end{equation}


**Definition:** Causal Sufficiency

*A set of variables X is usually said to be causally sufficient if there is no hidden common cause $C \notin X$ that is causing more than one variable in X* [@peters_elements_2017; @spirtes2010introduction] 

$$
P(Cancer|Smoking)=P(Smoking|Cancer) \times P(Cancer)
$$

**Markov Condition** 

@pearl2009causality defines the markov condition as follows: 

**Definition:** Causal Markov Condition

*Every Markovian causal model M induces a distribution P(x1,…, xn) that satisfies the parental Markov condition relative the causal diagram G associated with M; that is, each variable Xi is independent of all its nondescendants, given its parents PAi in G.*


$$
\begin{array}{l}
P_{x}(v)=\prod_{\left\{i \mid V_{i} \notin X\right\}} P\left(v_{i} \mid p a_{i}\right)\\
\text { for all } \boldsymbol{v} \text { consistent with } x
\end{array}
$$

## Time 

 why time is ignored.

# Pearl's Causal Hierachy 

\footnotesize
 |Method          | Action |  Example | Usage | 
|------------------|-------------|--------------------|-------------------|
| Association $P(a|b)$               | Co-occurrence             | What happened...               |(Un-)Supervised ML, BN, Reg.  
| Intervention $P(a|do(b),c)$       | Do-manipulation           | What happens if ...            |CBN,MDP,RL    
| Counterfactual $P(a_b|a`,b`)$     | Hypotheticals   | What would have happened if...           | SCM ,PO            

Table: Pearls Hierachy of Causation (2009)

\normalsize

## Association:

Associational methods ignore external changes outside of our data.
The interventional distribution has information on these external changes.
Note, that the intervention distribution is only defined in high level causal methods. 

Joint distribution

$P(c,s,g)= P(s)\times P(c|s,g) \times P(g)$ 

**Graph** 

One example is the bayesian network, which uses conditional probabilities instead of functions to describe the relationship between variables [@pearl2009causality]
In the probabilistic representation, we ignore latent factors [@creager; @pearl2009causality]. 

```{tikz, notwell,  fig.cap ="Probabilistic Model",  fig.align="center", echo =F, fig.show="hold", out.width="50%" }
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
\begin{tikzpicture}[
    sharp corners=2pt,
    inner sep=7pt,
    node distance=3cm,
    >=latex]
\tikzstyle{my node}=[draw, shape = circle, minimum height=1cm,minimum width=1cm]
\node[my node] (S){S};
\node[my node,right =1 cm of S](G){G};
\node[my node] at ($(S)!0.5!(G)-(0pt,1.5cm)$) (C) {C};
\draw[->] (S) -- (C);
\draw[->] (G) -- (C);
\end{tikzpicture}
```

## Intervention:

Here we can use @pearl2009causality do-calculus.

The do-calculus enables us to study the manipulation of parent nodes.

Instead of merely seeing the co-occurence of variables, we can actively manipulate the conditional distribution of one variable.
Commonly, one could use this method to evaluate different policies [@creager].
In our smoking example we can actively set the smoking behavior to a fixed value or a different conditional probability.


Joint distribution post intervention: $P_{S=s}(c,g)= P(c|S=s,g) \times P(g)$ 

There are various types of intervention.

I will illustrate atomic intervention and policy intervention based on our smoking example.

Suppose the government wants to examine, a different smoking behavior distribution will lower the number of lung cancer cases and medical expenses.
This different smoking behaviour could be the result of increased taxes, or e.g. finesup to a $1000 (as in the case of Singapore) for smoking in prohibited areas.
Alternative, the government could also undertake treatment by imposing higher tobacco taxes.
In this case we solely focus on the effect of a different smoking behavior on lung cancer for the sake of simplicity. 


In **atomic intervention,** we set a variable to a constant value.
As one can see in figure 3, c is constant that is not dependent on the latent factor, because in atomic intervention we do not derive the value of c based on the function S. 

```{tikz,fig.cap="Atomic Intervention" ,fig.align="center", echo =F}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
  \begin{tikzpicture}[
    sharp corners=2pt,
    inner sep=6pt,
    node distance=2cm,
    >=latex]
\tikzstyle{my node}=[draw, shape = circle, minimum height=1cm,minimum width=1cm]
\tikzstyle{latent}=[draw, shape = rectangle, minimum height=1cm,minimum width=1cm]
\node[my node, fill=gray!10] (p){c};
\node[my node, fill=gray!30] at ($(p)!0.5!(p)-(0pt,1.5cm)$) (G) {G};
\node[my node,right = 1 cm of G, fill=gray!30](C){C};
\node[latent,left = 1cm of G](UG){$U_G$};
\node[latent,right = 1cm of p](UC){$U_C$};
\draw[->] (UG) -- (G);
\draw[->] (UC) -- (C);
\draw[->] (p) -- (C);
\draw[->] (G) -- (C);
\end{tikzpicture}
```

Further, in mathematical notation the model would change as follows:

\begin{equation}
S:= s
\end{equation}
\begin{equation}
G:= f_G(U_G)
\end{equation}
\begin{equation}
C:= f_C(S,G,U_C)
\end{equation}

In **policy intervention** we specify a different conditional probability $(S=s)$ for an equation.
We can derive s from S, because we include information on the intervention distribution. 
This information cannot be obtained, if we directly specify our model as conditional probabilities.


```{tikz,fig.cap="Policy Model" ,fig.align="center", echo =F}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
  \begin{tikzpicture}[
    sharp corners=2pt,
    inner sep=6pt,
    node distance=2cm,
    >=latex]
\tikzstyle{my node}=[draw, shape = circle, minimum height=1cm,minimum width=1cm]
\tikzstyle{latent}=[draw, shape = rectangle, minimum height=1cm,minimum width=1cm]
\node[my node, fill=gray!10] (p){s};
\node[latent,left of=p](US){$U_S$};
\node[my node, fill=gray!30] at ($(p)!0.5!(p)-(0pt,1.5cm)$) (G) {G};
\node[my node,right = 1 cm of G, fill=gray!30](C){C};
\node[latent,left = 1cm of G](UG){$U_G$};
\node[latent,right = 1cm of p](UC){$U_C$};
\draw[->] (US) -- (p);
\draw[->] (UG) -- (G);
\draw[->] (UC) -- (C);
\draw[->] (p) -- (C);
\draw[->] (G) -- (C);
\end{tikzpicture}
```


where $\pi$ is our new conditional probability. 

One extension of policy intervention is off-policy intervention. 
**Off-policy intervention** models different intervention that is not in our historical data.
To accommodate the lack of data, we can estimate the intervention either based on model-based (e.g. regression),model-free estimates (propensity scores), or a mixture of these methods. 
For further information, see e.g. @oberst2019counterfactual or [@creager]. 

$do(t)$ -> replace function $T:=f_T(\pi)$ with different conditional probability (or constant) [@pearl2009causality].

**Counterfactuals:**

Process is described as follows:

(a) Abduction: Cast probability $P(u)$ as conditional probability $P(u|\epsilon)$ 
(b) Action: Exchange $(X = x)$ 
(c) Prediction: Compute $(Y = y)$

**Stable Unit Treatment Value Assumption {SUTVA}** 'The treatment that one unit receives does not change the effect of treatment for any other unit.'

**Consistency** The outcome Y agrees with the potential outcome corresponding to the treatment indicator.' 

**Ignorability** The potential outcomes are conditionally independent of treatment given some set of de-confounding variables. 
As suggested by [@hardtrecht], this condition ensures that we are dealing with a perfect randomized controlled trial. 

- First two hold for Counterfactuals in SCM
- third not testable but can check via backdoor criterion in SCM
- Source: [@hardtrecht]

# SCMs and Time 

largely ingore time 

time in mechanical modeling crucial [@peters_elements_2017].

- Time in Social Sciences: Often Vague 
- Time in Physical Sciences: Mechanical via **Differential equations** 
- dependence on prior time point and change in time contribute to the value at time point

Initial Value: 
$$
\mathbf{x}\left(t_{0}\right)=\mathbf{x}_{0}
$$

Derivative of function x with respect to time t: 

$$
\frac{d \mathbf{x}}{d t}=f(\mathbf{x}), \mathbf{x} \in \mathbb{R}^{d}
$$

Value of Function at time t + dt: 

$$
\mathbf{x}(t+d t)=\mathbf{x}(t)+d t \cdot f(\mathbf{x}(t))
$$

$$
\begin{array}{|l|l|l|l|l|}
\hline \text { model } & \begin{array}{l}
\text { IID setting }
\end{array} & \begin{array}{l}
\text { changing } \\
\text { distributions } 
\end{array} & \begin{array}{c}
\text { counter- } \\
\text { factual } \\
\text { questions }
\end{array} & \begin{array}{l}
\text { physical } \\
\text { insight }
\end{array} \\
\hline \begin{array}{l}
\text { mechanistic } \\
\text { model }
\end{array} & \mathrm{Y} & \mathrm{Y} & \mathrm{Y} & \mathrm{Y} \\
\hline \begin{array}{l}
\text { structural } \\
\text { causal model }
\end{array} & \mathrm{Y} & \mathrm{Y} & \mathrm{Y} & \mathrm{N} \\
\hline \begin{array}{l}
\text { causal } \\
\text { graphical } \\
\text { model }
\end{array} & \mathrm{Y} & \mathrm{Y} & \mathrm{N} & \mathrm{N} \\
\hline \begin{array}{l}
\text { statistical } \\
\text { model }
\end{array} & \mathrm{Y} & \mathrm{N} & \mathrm{N} & \mathrm{N} \\
\hline
\end{array}
$$

Table: Source: @peters_elements_2017

# Conclusion 

Structural causal models are flexible simulators to disentangle causality for manifold different queries.
There are many advantages of structural causal models:
(1) We are able to model latent fators forcing us to reconsider existing assumptions about the relationship in our data.
(2) Further, we get a underlying graphical representation including a mathematical language for this graphical systems to test causal assumptions that are otherwise untestable.
(3) Additionally, one is able to model queries beyond mere association going as far as dealing with hyptoethical situations. 
Simultaneously, 


\newpage 

# References

<div id="refs"></div>
\newpage

